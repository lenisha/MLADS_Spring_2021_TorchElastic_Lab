{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Setup Azure Kubernetes Infrastructure\n",
    "In this notebook we will setup \n",
    "- An AKS cluster with\n",
    "  - **GPU enabled Spot VM nodepool** for running elastic training\n",
    "  - **CPU VM nodepool** for running Rendezevous server - training control plane\n",
    "- Azure Storage Account for hosting training data and model training checkpoints\n",
    "- Deploy Kubernetes Components\n",
    "  - Torch Elastic Operator\n",
    "  - ETCD server for training control plane\n",
    "  - Azure Blob CSI Driver to map Blob storage to container as persistent volumes\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Define Variables\n",
    "Set variables required for the project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"f869415f-5cff-46a3-b728-20659d14d62d\"           # fill in\n",
    "resource_group = \"elastic-lab\"           # fill in\n",
    "region = \"eastus2\"                    # fill in\n",
    "\n",
    "storage_account_name = \"trainingdataen\"        # fill in\n",
    "storage_container_name = \"workerdata\"             \n",
    "\n",
    "aks_name = \"elasticaks\"    # feel free to replace or use this default\n",
    "aks_spot_nodepool = \"spotgpu\"       # feel free to replace or use this default\n",
    "aks_cpu_nodepool = \"cpuworkers\"     # feel free to replace or use this default\n",
    "aks_gpu_sku = \"Standard_NC12\"       # feel free to replace or use this default "
   ]
  },
  {
   "source": [
    "## Azure account login\n",
    "If you are not already logged in to an Azure account, the command below will initiate a login. This will pop up a browser where you can select your login. (if no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code` or login in WSL command  prompt and proceed to notebook)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az login -o table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set --subscription \"$subscription_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account show"
   ]
  },
  {
   "source": [
    "## Create Resource Group\n",
    "Azure encourages the use of groups to organize all the Azure components you deploy. That way it is easier to find them but also we can delete a number of resources simply by deleting the group."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n",
      "  \"id\": \"/subscriptions/f869415f-5cff-46a3-b728-20659d14d62d/resourceGroups/elastic-lab\",\n",
      "  \"location\": \"eastus2\",\n",
      "  \"managedBy\": null,\n",
      "  \"name\": \"elastic-lab\",\n",
      "  \"properties\": {\n",
      "    \"provisioningState\": \"Succeeded\"\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.Resources/resourceGroups\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az group create -l {region} -n {resource_group}"
   ]
  },
  {
   "source": [
    "## Create AKS Cluster and NodePools\n",
    "Below, we create the AKS cluster with default 1 system node (to save time, in production use more nodes as per best practices) in the resource group we created earlier. This step can take 5 or more minutes.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mThe behavior of this command has been altered by the following extension: aks-preview\u001b[0m\n",
      "{\n",
      "  \"aadProfile\": null,\n",
      "  \"addonProfiles\": {\n",
      "    \"KubeDashboard\": {\n",
      "      \"config\": null,\n",
      "      \"enabled\": false,\n",
      "      \"identity\": null\n",
      "    }\n",
      "  },\n",
      "  \"agentPoolProfiles\": [\n",
      "    {\n",
      "      \"availabilityZones\": null,\n",
      "      \"count\": 1,\n",
      "      \"enableAutoScaling\": null,\n",
      "      \"enableEncryptionAtHost\": false,\n",
      "      \"enableFips\": false,\n",
      "      \"enableNodePublicIp\": false,\n",
      "      \"gpuInstanceProfile\": null,\n",
      "      \"kubeletConfig\": null,\n",
      "      \"kubeletDiskType\": \"OS\",\n",
      "      \"linuxOsConfig\": null,\n",
      "      \"maxCount\": null,\n",
      "      \"maxPods\": 110,\n",
      "      \"minCount\": null,\n",
      "      \"mode\": \"System\",\n",
      "      \"name\": \"nodepool1\",\n",
      "      \"nodeImageVersion\": \"AKSUbuntu-1804gen2-2021.05.01\",\n",
      "      \"nodeLabels\": {},\n",
      "      \"nodePublicIpPrefixId\": null,\n",
      "      \"nodeTaints\": null,\n",
      "      \"orchestratorVersion\": \"1.18.17\",\n",
      "      \"osDiskSizeGb\": 128,\n",
      "      \"osDiskType\": \"Managed\",\n",
      "      \"osSku\": \"Ubuntu\",\n",
      "      \"osType\": \"Linux\",\n",
      "      \"podSubnetId\": null,\n",
      "      \"powerState\": {\n",
      "        \"code\": \"Running\"\n",
      "      },\n",
      "      \"provisioningState\": \"Succeeded\",\n",
      "      \"proximityPlacementGroupId\": null,\n",
      "      \"scaleSetEvictionPolicy\": null,\n",
      "      \"scaleSetPriority\": null,\n",
      "      \"spotMaxPrice\": null,\n",
      "      \"tags\": null,\n",
      "      \"type\": \"VirtualMachineScaleSets\",\n",
      "      \"upgradeSettings\": null,\n",
      "      \"vmSize\": \"Standard_D2s_v3\",\n",
      "      \"vnetSubnetId\": null\n",
      "    }\n",
      "  ],\n",
      "  \"apiServerAccessProfile\": null,\n",
      "  \"autoScalerProfile\": null,\n",
      "  \"autoUpgradeProfile\": null,\n",
      "  \"azurePortalFqdn\": \"elasticaks-elastic-lab-f86941-2ebefee0.portal.hcp.eastus2.azmk8s.io\",\n",
      "  \"disableLocalAccounts\": false,\n",
      "  \"diskEncryptionSetId\": null,\n",
      "  \"dnsPrefix\": \"elasticaks-elastic-lab-f86941\",\n",
      "  \"enablePodSecurityPolicy\": false,\n",
      "  \"enableRbac\": true,\n",
      "  \"extendedLocation\": null,\n",
      "  \"fqdn\": \"elasticaks-elastic-lab-f86941-2ebefee0.hcp.eastus2.azmk8s.io\",\n",
      "  \"fqdnSubdomain\": null,\n",
      "  \"httpProxyConfig\": null,\n",
      "  \"id\": \"/subscriptions/f869415f-5cff-46a3-b728-20659d14d62d/resourcegroups/elastic-lab/providers/Microsoft.ContainerService/managedClusters/elasticaks\",\n",
      "  \"identity\": {\n",
      "    \"principalId\": \"e4cb600f-5977-43bd-b521-b7a379bfdbcd\",\n",
      "    \"tenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "    \"type\": \"SystemAssigned\",\n",
      "    \"userAssignedIdentities\": null\n",
      "  },\n",
      "  \"identityProfile\": {\n",
      "    \"kubeletidentity\": {\n",
      "      \"clientId\": \"0cdd15f0-0466-4ee0-93ef-a0b1bf5a8c69\",\n",
      "      \"objectId\": \"22ef7dcb-5a8b-42b5-b801-30e171c48f7d\",\n",
      "      \"resourceId\": \"/subscriptions/f869415f-5cff-46a3-b728-20659d14d62d/resourcegroups/MC_elastic-lab_elasticaks_eastus2/providers/Microsoft.ManagedIdentity/userAssignedIdentities/elasticaks-agentpool\"\n",
      "    }\n",
      "  },\n",
      "  \"kubernetesVersion\": \"1.18.17\",\n",
      "  \"linuxProfile\": {\n",
      "    \"adminUsername\": \"azureuser\",\n",
      "    \"ssh\": {\n",
      "      \"publicKeys\": [\n",
      "        {\n",
      "          \"keyData\": \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDG3YcTX3MUP4GvT1Gt2OoJaaKwKwnI3OBHUb4KqeU7zUJj+6PkIFT4OloX7Wt092CoAtIBBEmLuOZo3cFPa9l/niihoUbDcETQYgWBh+xA9a10vdBLg7Ls3UbRRg6xmpeeeDOCKJZW5rV/e4hM+vpQiQu3mZn4Cnksb38OZp7lRc+Fk4TLIreoVj+5GLYTjvYGouy8sKYqQxsZoSkim5AqwifN8gBAJm7Zf+JwDf8suq8rSJ0cdDJ4MHhFvVZqDs/YPk58DwlNNW1U3/5mqhbHaKLnS8QAOIubnIJu1lBho9sAUGoocvx154ygWfORuKBvSgIc176k1BGea+m+xDBL\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"location\": \"eastus2\",\n",
      "  \"maxAgentPools\": 100,\n",
      "  \"name\": \"elasticaks\",\n",
      "  \"networkProfile\": {\n",
      "    \"dnsServiceIp\": \"10.0.0.10\",\n",
      "    \"dockerBridgeCidr\": \"172.17.0.1/16\",\n",
      "    \"loadBalancerProfile\": {\n",
      "      \"allocatedOutboundPorts\": null,\n",
      "      \"effectiveOutboundIps\": [\n",
      "        {\n",
      "          \"id\": \"/subscriptions/f869415f-5cff-46a3-b728-20659d14d62d/resourceGroups/MC_elastic-lab_elasticaks_eastus2/providers/Microsoft.Network/publicIPAddresses/2036f068-98aa-4408-a1d6-ea14fc469fa5\",\n",
      "          \"resourceGroup\": \"MC_elastic-lab_elasticaks_eastus2\"\n",
      "        }\n",
      "      ],\n",
      "      \"idleTimeoutInMinutes\": null,\n",
      "      \"managedOutboundIps\": {\n",
      "        \"count\": 1\n",
      "      },\n",
      "      \"outboundIpPrefixes\": null,\n",
      "      \"outboundIps\": null\n",
      "    },\n",
      "    \"loadBalancerSku\": \"Standard\",\n",
      "    \"networkMode\": null,\n",
      "    \"networkPlugin\": \"kubenet\",\n",
      "    \"networkPolicy\": null,\n",
      "    \"outboundType\": \"loadBalancer\",\n",
      "    \"podCidr\": \"10.244.0.0/16\",\n",
      "    \"serviceCidr\": \"10.0.0.0/16\"\n",
      "  },\n",
      "  \"nodeResourceGroup\": \"MC_elastic-lab_elasticaks_eastus2\",\n",
      "  \"podIdentityProfile\": null,\n",
      "  \"powerState\": {\n",
      "    \"code\": \"Running\"\n",
      "  },\n",
      "  \"privateFqdn\": null,\n",
      "  \"privateLinkResources\": null,\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"elastic-lab\",\n",
      "  \"servicePrincipalProfile\": {\n",
      "    \"clientId\": \"msi\",\n",
      "    \"secret\": null\n",
      "  },\n",
      "  \"sku\": {\n",
      "    \"name\": \"Basic\",\n",
      "    \"tier\": \"Free\"\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.ContainerService/ManagedClusters\",\n",
      "  \"windowsProfile\": null\n",
      "}\n",
      "\u001b[K\u001b[0mCPU times: user 11.7 s, sys: 3.64 s, total: 15.3 s\n",
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!az aks create --resource-group {resource_group} \\\n",
    "    --name {aks_name} \\\n",
    "    --node-vm-size Standard_D2s_v3 \\\n",
    "    --node-count 1 \\\n",
    "    --location {region}  \\\n",
    "    --kubernetes-version 1.18.17 \\\n",
    "    --generate-ssh-keys"
   ]
  },
  {
   "source": [
    "## Connect to AKS Cluster\n",
    "To configure kubectl to connect to Kubernetes cluster, run the following command"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mThe behavior of this command has been altered by the following extension: aks-preview\u001b[0m\n",
      "Merged \"elasticaks\" as current context in /home/lenisha/.kube/config\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az aks get-credentials --resource-group {resource_group} --name {aks_name}"
   ]
  },
  {
   "source": [
    "Let's verify connection by listing the nodes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NAME                                STATUS   ROLES   AGE     VERSION\naks-nodepool1-40607851-vmss000000   Ready    agent   2m24s   v1.18.17\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "source": [
    "Taint System node with `CriticalAddonsOnly` taint so it is available only for system workloads"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "node/aks-nodepool1-40607851-vmss000000 modified\n"
     ]
    }
   ],
   "source": [
    "!kubectl taint nodes -l agentpool=nodepool1 CriticalAddonsOnly=true:NoSchedule --overwrite\n"
   ]
  },
  {
   "source": [
    "## Create GPU enabled and CPU Node Pools\n",
    "To create GPU enabled nodepool, will use fully configured AKS image that contains the NVIDIA device plugin for Kubenetes, see [Use the AKS specialized GPU image (preview)](https://docs.microsoft.com/en-us/azure/aks/gpu-cluster#use-the-aks-specialized-gpu-image-preview). Creating nodepools could take five or more minutes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mOnce the feature 'GPUDedicatedVHDPreview' is registered, invoking 'az provider register -n Microsoft.ContainerService' is required to get the change propagated\u001b[0m\n",
      "{\n",
      "  \"id\": \"/subscriptions/f869415f-5cff-46a3-b728-20659d14d62d/providers/Microsoft.Features/providers/Microsoft.ContainerService/features/GPUDedicatedVHDPreview\",\n",
      "  \"name\": \"Microsoft.ContainerService/GPUDedicatedVHDPreview\",\n",
      "  \"properties\": {\n",
      "    \"state\": \"Registered\"\n",
      "  },\n",
      "  \"type\": \"Microsoft.Features/providers/features\"\n",
      "}\n",
      "\u001b[0mName                                               State\n",
      "-------------------------------------------------  ----------\n",
      "Microsoft.ContainerService/GPUDedicatedVHDPreview  Registered\n",
      "\u001b[33mExtension 'aks-preview' is already installed.\u001b[0m\n",
      "\u001b[0mCPU times: user 347 ms, sys: 221 ms, total: 569 ms\n",
      "Wall time: 8.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!az feature register --name GPUDedicatedVHDPreview --namespace Microsoft.ContainerService\n",
    "!az feature list -o table --query \"[?contains(name, 'Microsoft.ContainerService/GPUDedicatedVHDPreview')].{Name:name,State:properties.state}\"\n",
    "!az provider register --namespace Microsoft.ContainerService\n",
    "!az extension add --name aks-preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mThe behavior of this command has been altered by the following extension: aks-preview\u001b[0m\n",
      "{\n",
      "  \"agentPoolType\": \"VirtualMachineScaleSets\",\n",
      "  \"availabilityZones\": null,\n",
      "  \"count\": 3,\n",
      "  \"enableAutoScaling\": true,\n",
      "  \"enableEncryptionAtHost\": false,\n",
      "  \"enableFips\": false,\n",
      "  \"enableNodePublicIp\": false,\n",
      "  \"gpuInstanceProfile\": null,\n",
      "  \"id\": \"/subscriptions/f869415f-5cff-46a3-b728-20659d14d62d/resourcegroups/elastic-lab/providers/Microsoft.ContainerService/managedClusters/elasticaks/agentPools/spotgpu\",\n",
      "  \"kubeletConfig\": null,\n",
      "  \"kubeletDiskType\": \"OS\",\n",
      "  \"linuxOsConfig\": null,\n",
      "  \"maxCount\": 3,\n",
      "  \"maxPods\": 110,\n",
      "  \"minCount\": 1,\n",
      "  \"mode\": \"User\",\n",
      "  \"name\": \"spotgpu\",\n",
      "  \"nodeImageVersion\": \"AKSUbuntu-1804gpu-2021.05.01\",\n",
      "  \"nodeLabels\": {\n",
      "    \"kubernetes.azure.com/scalesetpriority\": \"spot\"\n",
      "  },\n",
      "  \"nodePublicIpPrefixId\": null,\n",
      "  \"nodeTaints\": [\n",
      "    \"kubernetes.azure.com/scalesetpriority=spot:NoSchedule\"\n",
      "  ],\n",
      "  \"orchestratorVersion\": \"1.18.17\",\n",
      "  \"osDiskSizeGb\": 128,\n",
      "  \"osDiskType\": \"Managed\",\n",
      "  \"osSku\": \"Ubuntu\",\n",
      "  \"osType\": \"Linux\",\n",
      "  \"podSubnetId\": null,\n",
      "  \"powerState\": {\n",
      "    \"code\": \"Running\"\n",
      "  },\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"proximityPlacementGroupId\": null,\n",
      "  \"resourceGroup\": \"elastic-lab\",\n",
      "  \"scaleSetEvictionPolicy\": \"Delete\",\n",
      "  \"scaleSetPriority\": \"Spot\",\n",
      "  \"spotMaxPrice\": -1.0,\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.ContainerService/managedClusters/agentPools\",\n",
      "  \"upgradeSettings\": {\n",
      "    \"maxSurge\": null\n",
      "  },\n",
      "  \"vmSize\": \"Standard_NC12\",\n",
      "  \"vnetSubnetId\": null\n",
      "}\n",
      "\u001b[K\u001b[0mCPU times: user 7.24 s, sys: 2.38 s, total: 9.62 s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!az aks nodepool add \\\n",
    "    --resource-group {resource_group} \\\n",
    "    --cluster-name {aks_name} \\\n",
    "    --name {aks_spot_nodepool} \\\n",
    "    --priority Spot \\\n",
    "    --eviction-policy Delete \\\n",
    "    --spot-max-price -1 \\\n",
    "    --enable-cluster-autoscaler \\\n",
    "    --min-count 1 \\\n",
    "    --max-count 3 \\\n",
    "    --node-vm-size {aks_gpu_sku} \\\n",
    "    --aks-custom-headers UseGPUDedicatedVHD=true,usegen2vm=true"
   ]
  },
  {
   "source": [
    "## Verify GPU is available on Kubernetes Node\n",
    "Now use the kubectl describe node command to confirm that the GPUs are schedulable. Under the Capacity section, the GPU should list as nvidia.com/gpu: 2."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Name:               aks-spotgpu-40607851-vmss000001\nRoles:              agent\nLabels:             accelerator=nvidia\n                    agentpool=spotgpu\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_NC12\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eastus2\n                    failure-domain.beta.kubernetes.io/zone=0\n                    kubernetes.azure.com/cluster=MC_elastic-lab_elasticaks_eastus2\n                    kubernetes.azure.com/node-image-version=AKSUbuntu-1804gpu-2021.05.01\n                    kubernetes.azure.com/role=agent\n                    kubernetes.azure.com/scalesetpriority=spot\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=aks-spotgpu-40607851-vmss000001\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=agent\n                    node-role.kubernetes.io/agent=\n                    node.kubernetes.io/instance-type=Standard_NC12\n                    storageprofile=managed\n                    storagetier=Standard_LRS\n                    topology.kubernetes.io/region=eastus2\n                    topology.kubernetes.io/zone=0\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 23 May 2021 17:55:11 -0400\nTaints:             kubernetes.azure.com/scalesetpriority=spot:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  aks-spotgpu-40607851-vmss000001\n  AcquireTime:     <unset>\n  RenewTime:       Sun, 23 May 2021 18:14:22 -0400\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sun, 23 May 2021 17:55:28 -0400   Sun, 23 May 2021 17:55:28 -0400   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Sun, 23 May 2021 18:10:23 -0400   Sun, 23 May 2021 17:55:11 -0400   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sun, 23 May 2021 18:10:23 -0400   Sun, 23 May 2021 17:55:11 -0400   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sun, 23 May 2021 18:10:23 -0400   Sun, 23 May 2021 17:55:11 -0400   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sun, 23 May 2021 18:10:23 -0400   Sun, 23 May 2021 17:55:21 -0400   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  Hostname:    aks-spotgpu-40607851-vmss000001\n  InternalIP:  10.240.0.6\nCapacity:\n  attachable-volumes-azure-disk:  48\n  cpu:                            12\n  ephemeral-storage:              129900528Ki\n  hugepages-1Gi:                  0\n  hugepages-2Mi:                  0\n  memory:                         115387540Ki\n  nvidia.com/gpu:                 2\n  pods:                           110\nAllocatable:\n  attachable-volumes-azure-disk:  48\n  cpu:                            11780m\n  ephemeral-storage:              119716326407\n  hugepages-1Gi:                  0\n  hugepages-2Mi:                  0\n  memory:                         105854100Ki\n  nvidia.com/gpu:                 2\n  pods:                           110\nSystem Info:\n  Machine ID:                 cb69889184dc419ab70c4fbfd495382d\n  System UUID:                23debf63-1765-4e46-9aca-eeacfaf7bb76\n  Boot ID:                    0255b07c-8ec5-4ed8-8fbe-bd247e7b07a4\n  Kernel Version:             5.4.0-1046-azure\n  OS Image:                   Ubuntu 18.04.5 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://19.3.14\n  Kubelet Version:            v1.18.17\n  Kube-Proxy Version:         v1.18.17\nPodCIDR:                      10.244.7.0/24\nPodCIDRs:                     10.244.7.0/24\nProviderID:                   azure:///subscriptions/f869415f-5cff-46a3-b728-20659d14d62d/resourceGroups/mc_elastic-lab_elasticaks_eastus2/providers/Microsoft.Compute/virtualMachineScaleSets/aks-spotgpu-40607851-vmss/virtualMachines/1\nNon-terminated Pods:          (1 in total)\n  Namespace                   Name                CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                ------------  ----------  ---------------  -------------  ---\n  kube-system                 kube-proxy-b5dr5    100m (0%)     0 (0%)      0 (0%)           0 (0%)         19m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests   Limits\n  --------                       --------   ------\n  cpu                            100m (0%)  0 (0%)\n  memory                         0 (0%)     0 (0%)\n  ephemeral-storage              0 (0%)     0 (0%)\n  hugepages-1Gi                  0 (0%)     0 (0%)\n  hugepages-2Mi                  0 (0%)     0 (0%)\n  attachable-volumes-azure-disk  0          0\n  nvidia.com/gpu                 0          0\nEvents:\n  Type    Reason                   Age                From        Message\n  ----    ------                   ----               ----        -------\n  Normal  Starting                 50m                kubelet     Starting kubelet.\n  Normal  NodeHasSufficientMemory  50m (x2 over 50m)  kubelet     Node aks-spotgpu-40607851-vmss000001 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    50m (x2 over 50m)  kubelet     Node aks-spotgpu-40607851-vmss000001 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     50m (x2 over 50m)  kubelet     Node aks-spotgpu-40607851-vmss000001 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  50m                kubelet     Updated Node Allocatable limit across pods\n  Normal  Starting                 50m                kube-proxy  Starting kube-proxy.\n  Normal  NodeReady                50m                kubelet     Node aks-spotgpu-40607851-vmss000001 status is now: NodeReady\n  Normal  Starting                 19m                kubelet     Starting kubelet.\n  Normal  NodeHasSufficientMemory  19m (x2 over 19m)  kubelet     Node aks-spotgpu-40607851-vmss000001 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    19m (x2 over 19m)  kubelet     Node aks-spotgpu-40607851-vmss000001 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     19m (x2 over 19m)  kubelet     Node aks-spotgpu-40607851-vmss000001 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  19m                kubelet     Updated Node Allocatable limit across pods\n  Normal  Starting                 19m                kube-proxy  Starting kube-proxy.\n  Normal  NodeReady                19m                kubelet     Node aks-spotgpu-40607851-vmss000001 status is now: NodeReady\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe node -l kubernetes.azure.com/scalesetpriority=spot"
   ]
  },
  {
   "source": [
    "## Create CPU NodePool for running ETCD"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mThe behavior of this command has been altered by the following extension: aks-preview\u001b[0m\n",
      "{\n",
      "  \"agentPoolType\": \"VirtualMachineScaleSets\",\n",
      "  \"availabilityZones\": null,\n",
      "  \"count\": 3,\n",
      "  \"enableAutoScaling\": true,\n",
      "  \"enableEncryptionAtHost\": false,\n",
      "  \"enableFips\": false,\n",
      "  \"enableNodePublicIp\": false,\n",
      "  \"gpuInstanceProfile\": null,\n",
      "  \"id\": \"/subscriptions/f869415f-5cff-46a3-b728-20659d14d62d/resourcegroups/elastic-lab/providers/Microsoft.ContainerService/managedClusters/elasticaks/agentPools/cpuworkers\",\n",
      "  \"kubeletConfig\": null,\n",
      "  \"kubeletDiskType\": \"OS\",\n",
      "  \"linuxOsConfig\": null,\n",
      "  \"maxCount\": 3,\n",
      "  \"maxPods\": 110,\n",
      "  \"minCount\": 1,\n",
      "  \"mode\": \"User\",\n",
      "  \"name\": \"cpuworkers\",\n",
      "  \"nodeImageVersion\": \"AKSUbuntu-1804gen2-2021.05.01\",\n",
      "  \"nodeLabels\": null,\n",
      "  \"nodePublicIpPrefixId\": null,\n",
      "  \"nodeTaints\": null,\n",
      "  \"orchestratorVersion\": \"1.18.17\",\n",
      "  \"osDiskSizeGb\": 128,\n",
      "  \"osDiskType\": \"Managed\",\n",
      "  \"osSku\": \"Ubuntu\",\n",
      "  \"osType\": \"Linux\",\n",
      "  \"podSubnetId\": null,\n",
      "  \"powerState\": {\n",
      "    \"code\": \"Running\"\n",
      "  },\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"proximityPlacementGroupId\": null,\n",
      "  \"resourceGroup\": \"elastic-lab\",\n",
      "  \"scaleSetEvictionPolicy\": null,\n",
      "  \"scaleSetPriority\": null,\n",
      "  \"spotMaxPrice\": null,\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.ContainerService/managedClusters/agentPools\",\n",
      "  \"upgradeSettings\": {\n",
      "    \"maxSurge\": null\n",
      "  },\n",
      "  \"vmSize\": \"Standard_D2s_v3\",\n",
      "  \"vnetSubnetId\": null\n",
      "}\n",
      "\u001b[K\u001b[0mCPU times: user 7.13 s, sys: 2.4 s, total: 9.53 s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "!az aks nodepool add \\\n",
    "  --resource-group {resource_group} \\\n",
    "    --cluster-name {aks_name} \\\n",
    "    --name {aks_cpu_nodepool} \\\n",
    "    --enable-cluster-autoscaler \\\n",
    "    --min-count 1 \\\n",
    "    --max-count 3 \\\n",
    "    --node-vm-size Standard_D2s_v3 "
   ]
  },
  {
   "source": [
    "## Verify Taints on the Kubernetes nodes\n",
    "Verify that system pool and have the Taints `CriticalAddonsOnly` and `kubernetes.azure.com/scalesetpriority` respectively   \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1;30mnull\u001b[0m\n\u001b[1;30mnull\u001b[0m\n\u001b[1;30mnull\u001b[0m\n\u001b[1;39m[\n  \u001b[1;39m{\n    \u001b[0m\u001b[34;1m\"effect\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"NoSchedule\"\u001b[0m\u001b[1;39m,\n    \u001b[0m\u001b[34;1m\"key\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"CriticalAddonsOnly\"\u001b[0m\u001b[1;39m,\n    \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"true\"\u001b[0m\u001b[1;39m\n  \u001b[1;39m}\u001b[0m\u001b[1;39m\n\u001b[1;39m]\u001b[0m\n\u001b[1;39m[\n  \u001b[1;39m{\n    \u001b[0m\u001b[34;1m\"effect\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"NoSchedule\"\u001b[0m\u001b[1;39m,\n    \u001b[0m\u001b[34;1m\"key\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"kubernetes.azure.com/scalesetpriority\"\u001b[0m\u001b[1;39m,\n    \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"spot\"\u001b[0m\u001b[1;39m\n  \u001b[1;39m}\u001b[0m\u001b[1;39m\n\u001b[1;39m]\u001b[0m\n\u001b[1;39m[\n  \u001b[1;39m{\n    \u001b[0m\u001b[34;1m\"effect\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"NoSchedule\"\u001b[0m\u001b[1;39m,\n    \u001b[0m\u001b[34;1m\"key\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"kubernetes.azure.com/scalesetpriority\"\u001b[0m\u001b[1;39m,\n    \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"spot\"\u001b[0m\u001b[1;39m\n  \u001b[1;39m}\u001b[0m\u001b[1;39m\n\u001b[1;39m]\u001b[0m\n\u001b[1;39m[\n  \u001b[1;39m{\n    \u001b[0m\u001b[34;1m\"effect\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"NoSchedule\"\u001b[0m\u001b[1;39m,\n    \u001b[0m\u001b[34;1m\"key\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"kubernetes.azure.com/scalesetpriority\"\u001b[0m\u001b[1;39m,\n    \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"spot\"\u001b[0m\u001b[1;39m\n  \u001b[1;39m}\u001b[0m\u001b[1;39m\n\u001b[1;39m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes -o json | jq '.items[].spec.taints'"
   ]
  },
  {
   "source": [
    "# Create Storage Account for training data \n",
    "In this section of the notebook, we'll create an Azure blob storage that we'll use throughout the tutorial. This object store will be used to store input images and save checkpoints. Use `az cli` to create the account"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"Succeeded\"\n",
      "\u001b[K\u001b[0mCPU times: user 1.06 s, sys: 456 ms, total: 1.51 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!az storage account create -n {storage_account_name} -g {resource_group} --query 'provisioningState'\n"
   ]
  },
  {
   "source": [
    "Grab the keys of the storage account that was just created.We would need them for binding Kubernetes Persistent Volume. The --quote '[0].value' part of the command simply means to select the value of the zero-th indexed of the set of keys."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = !az storage account keys list --account-name {storage_account_name} -g {resource_group} --query '[0].value'"
   ]
  },
  {
   "source": [
    "\n",
    "The stdout from the command above is stored in a string array of 1. Select the element in the array and ttrip opening and closing quotation marks."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_account_key = str(key[0][1:-1]) # this is used to strip opening and closing quotation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n",
      "  \"created\": true\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# create storage container\n",
    "\n",
    "!az storage container create \\\n",
    "    --account-name {storage_account_name} \\\n",
    "    --account-key {storage_account_key} \\\n",
    "    --name {storage_container_name}"
   ]
  },
  {
   "source": [
    "# Install Kubernetes Blob CSI Driver \n",
    "[Azure Blob Storage CSI driver for Kubernetes](https://github.com/kubernetes-sigs/blob-csi-driver) allows Kubernetes to access Azure Storage. We will deploy it using Helm3 package manager as described in the docs https://github.com/kubernetes-sigs/blob-csi-driver/tree/master/charts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"blob-csi-driver\" already exists with the same configuration, skipping\n",
      "Error: cannot re-use a name that is still in use\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!helm repo add blob-csi-driver https://raw.githubusercontent.com/kubernetes-sigs/blob-csi-driver/master/charts\n",
    "!helm install blob-csi-driver blob-csi-driver/blob-csi-driver --namespace kube-system --version v1.1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NAME                                   READY   STATUS    RESTARTS   AGE\ncsi-blob-controller-56956c6dbd-bhnhx   4/4     Running   0          6m7s\ncsi-blob-controller-56956c6dbd-bj8s2   4/4     Running   0          6m7s\ncsi-blob-node-4ff9l                    3/3     Running   0          6m7s\ncsi-blob-node-5vsp7                    3/3     Running   0          6m7s\ncsi-blob-node-94k5j                    3/3     Running   0          4m21s\ncsi-blob-node-xhvwp                    3/3     Running   0          6m7s\n"
     ]
    }
   ],
   "source": [
    "!kubectl -n kube-system get pods -l \"app.kubernetes.io/instance=blob-csi-driver\""
   ]
  },
  {
   "source": [
    "## Create Persistent Volume for Azure Blob\n",
    "For more details on creating   `PersistentVolume` using CSI driver refer to https://github.com/kubernetes-sigs/blob-csi-driver/blob/master/deploy/example/e2e_usage.md"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error from server (AlreadyExists): namespaces \"elastic-job\" already exists\n",
      "Error from server (AlreadyExists): secrets \"azure-blobsecret\" already exists\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace elastic-job\n",
    "# Create secret to access storage account\n",
    "!kubectl create secret generic azure-blobsecret --from-literal azurestorageaccountname={storage_account_name} --from-literal azurestorageaccountkey=\"{storage_account_key}\" --type=Opaque -n elastic-job\n",
    "\n"
   ]
  },
  {
   "source": [
    "Persistent Volume YAML definition is in `kube/azure-blobfules-pv.yaml` with fields pointing to secret created above and containername we created in storage account:\n",
    "```\n",
    "  csi:\n",
    "    driver: blob.csi.azure.com\n",
    "    readOnly: false\n",
    "    volumeHandle: trainingdata  # make sure this volumeid is unique in the cluster\n",
    "    volumeAttributes:\n",
    "      containerName: workerdata # Modify if changed in Notebook\n",
    "    nodeStageSecretRef:\n",
    "      name: azure-blobsecret\n",
    "      namespace: elastic-job\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "persistentvolume/pv-blob created\n",
      "persistentvolumeclaim/pvc-blob created\n"
     ]
    }
   ],
   "source": [
    "# Create PersistentVolume and PersistenVollumeClaim for container mounts\n",
    "!kubectl apply -f kube/azure-blobfuse-pv.yaml"
   ]
  },
  {
   "source": [
    "Now all the Kubernetes preparation steps are done, we will look at adjusting training script to be able to run it in Elastic Fault tolerant way [Step 2 Distributed Training Script](/Step2-DistributedTraining.md)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}